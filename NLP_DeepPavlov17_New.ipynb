{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srRyzhov/Hackathon/blob/main/NLP_DeepPavlov17_New.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D419LafG8pZr"
      },
      "outputs": [],
      "source": [
        "! pip install -U accelerate\n",
        "! pip install -U transformers\n",
        "! pip install xlwt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYJCS7QT7obD",
        "outputId": "78cdfe58-a248-4187-9c3e-1c0f975c2a5f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('4.33.1', '0.22.0')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from transformers import BertForSequenceClassification, BertTokenizer\n",
        "from transformers import TrainingArguments\n",
        "from transformers import Trainer\n",
        "\n",
        "import transformers\n",
        "import accelerate\n",
        "transformers.__version__, accelerate.__version__\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqKk25aysz-m"
      },
      "source": [
        "Загрузить файл CRA_train_1200.xlsx !"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_excel('/content/CRA_train_1200.xlsx', engine = 'openpyxl', index_col = 0)"
      ],
      "metadata": {
        "id": "AhUoG3IBt00i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# На 17\n",
        "train_text, test_text, train_labels, test_labels = train_test_split(train_df['pr_txt'].astype('str'),train_df['Уровень рейтинга'].astype('str'), test_size=0.1, random_state=36)"
      ],
      "metadata": {
        "id": "jwrX9CE2t0mr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_df = pd.read_excel('/content/CRA_test_422.xlsx', engine = 'openpyxl', index_col = 0)\n",
        "fin_text = train_df['pr_txt']\n",
        "#fin_labels = train_df['Категория']\n",
        "fin_labels = train_df['Уровень рейтинга']"
      ],
      "metadata": {
        "id": "fqTfUynVD-oR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zuw3KZZw-9Jx"
      },
      "source": [
        "\n",
        "Тексты для классификации - train_text\n",
        "\n",
        "Метки классов, соответствующие текстам - train_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WdZ6S0Xa3fA-"
      },
      "outputs": [],
      "source": [
        "def seed_all(seed_value):\n",
        "    random.seed(seed_value)\n",
        "    np.random.seed(seed_value)\n",
        "    torch.manual_seed(seed_value)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed_value)\n",
        "        torch.cuda.manual_seed_all(seed_value)\n",
        "        torch.backends.cudnn.benchmark = True\n",
        "        torch.backends.cudnn.deterministic = False\n",
        "seed_all(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VF_ulcvF2-7y"
      },
      "outputs": [],
      "source": [
        "# Модель 'DeepPavlov/rubert-base-cased'  Внимание: 7 или 17 выбрать\n",
        "model_name = 'DeepPavlov/rubert-base-cased'\n",
        "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=17) # 17!!!!\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMCVYxGzosEm"
      },
      "outputs": [],
      "source": [
        "tokens_train = tokenizer.batch_encode_plus(\n",
        "    train_text.values,\n",
        "    max_length = 512,\n",
        "    padding = 'max_length',\n",
        "    truncation = True\n",
        ")\n",
        "\n",
        "tokens_test = tokenizer.batch_encode_plus(\n",
        "    test_text.values,\n",
        "    max_length = 512,\n",
        "    padding = 'max_length',\n",
        "    truncation = True\n",
        ")\n",
        "\n",
        "# tokens_fin = tokenizer.batch_encode_plus(\n",
        "#     fin_text.values,\n",
        "#     max_length = 512,\n",
        "#     padding = 'max_length',\n",
        "#     truncation = True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Создание и обучение кодировщика на тренировочных метках\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(train_labels)\n",
        "\n",
        "# Преобразование тренировочных и тестовых меток в целочисленные значения\n",
        "train_labels_encoded = label_encoder.transform(train_labels)\n",
        "test_labels_encoded = label_encoder.transform(test_labels)\n",
        "#fin_labels_encoded = label_encoder.transform(fin_labels)\n",
        "\n",
        "# Получение соответствия между исходными метками и их целочисленными значениями\n",
        "label_mapping = {label: value for label, value in zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_))}\n"
      ],
      "metadata": {
        "id": "HmBoG6bfOk4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fgt_5x42Nz9R"
      },
      "outputs": [],
      "source": [
        "#оборачиваем токенизированные текстовые данные в torch Dataset:\n",
        "class Data(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
        "        item[\"labels\"] = torch.tensor([self.labels[idx]])\n",
        "        return item\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = Data(tokens_train, train_labels_encoded)\n",
        "test_dataset = Data(tokens_test, test_labels_encoded)\n",
        "#fin_dataset = Data(tokens_fin, fin_labels_encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "twSP0VY4T34A"
      },
      "outputs": [],
      "source": [
        "#расчет метрики - F1\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    f1 = f1_score(labels, preds, average='micro')\n",
        "    # one of [None, 'micro', 'macro', 'weighted']\n",
        "    return {'F1': f1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mtb35u1TUKSA"
      },
      "outputs": [],
      "source": [
        "#параметры для обучения:\n",
        "training_args = TrainingArguments(\n",
        "    output_dir = './results', #Выходной каталог\n",
        "    num_train_epochs = 20, #Кол-во эпох для обучения\n",
        "    per_device_train_batch_size = 12, #Размер пакета для каждого устройства во время обучения\n",
        "    per_device_eval_batch_size = 12, #Размер пакета для каждого устройства во время валидации\n",
        "    weight_decay =0.01, #Понижение весов\n",
        "    logging_dir = './logs', #Каталог для хранения журналов\n",
        "    load_best_model_at_end = True, #Загружать ли лучшую модель после обучения\n",
        "    learning_rate = 1e-5, #Скорость обучения\n",
        "    evaluation_strategy ='epoch', #Валидация после каждой эпохи (можно сделать после конкретного кол-ва шагов)\n",
        "    logging_strategy = 'epoch', #Логирование после каждой эпохи\n",
        "    save_strategy = 'epoch', #Сохранение после каждой эпохи\n",
        "    save_total_limit = 1,\n",
        "    seed=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DrzcM3orUhEB"
      },
      "outputs": [],
      "source": [
        "#Передача в trainer предообученной модели, tokenizer, данных для обучения, данных для валидации и способа расчета метрики\n",
        "trainer = Trainer(model=model,\n",
        "                  tokenizer = tokenizer,\n",
        "                  args = training_args,\n",
        "                  train_dataset = train_dataset,\n",
        "                  eval_dataset = test_dataset,\n",
        "                  compute_metrics = compute_metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TmWyoLelVPls",
        "outputId": "4cb13f5d-579f-4368-9d0b-f64c50947f2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 737
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1800' max='1800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1800/1800 43:29, Epoch 20/20]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.677900</td>\n",
              "      <td>2.576063</td>\n",
              "      <td>0.175000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.474500</td>\n",
              "      <td>2.401039</td>\n",
              "      <td>0.216667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.177000</td>\n",
              "      <td>2.139117</td>\n",
              "      <td>0.308333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.943100</td>\n",
              "      <td>1.971331</td>\n",
              "      <td>0.350000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.726400</td>\n",
              "      <td>1.800245</td>\n",
              "      <td>0.408333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.555500</td>\n",
              "      <td>1.609684</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.392500</td>\n",
              "      <td>1.545643</td>\n",
              "      <td>0.516667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.240400</td>\n",
              "      <td>1.451628</td>\n",
              "      <td>0.583333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.120000</td>\n",
              "      <td>1.352301</td>\n",
              "      <td>0.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.997400</td>\n",
              "      <td>1.303927</td>\n",
              "      <td>0.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.910400</td>\n",
              "      <td>1.243066</td>\n",
              "      <td>0.591667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.817700</td>\n",
              "      <td>1.257664</td>\n",
              "      <td>0.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.743000</td>\n",
              "      <td>1.188756</td>\n",
              "      <td>0.641667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.690800</td>\n",
              "      <td>1.204300</td>\n",
              "      <td>0.625000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.631200</td>\n",
              "      <td>1.290959</td>\n",
              "      <td>0.583333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.592000</td>\n",
              "      <td>1.163137</td>\n",
              "      <td>0.641667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.550700</td>\n",
              "      <td>1.188382</td>\n",
              "      <td>0.633333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.531500</td>\n",
              "      <td>1.152349</td>\n",
              "      <td>0.641667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.503800</td>\n",
              "      <td>1.147497</td>\n",
              "      <td>0.641667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.489000</td>\n",
              "      <td>1.146329</td>\n",
              "      <td>0.641667</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1800, training_loss=1.188238959842258, metrics={'train_runtime': 2614.5372, 'train_samples_per_second': 8.262, 'train_steps_per_second': 0.688, 'total_flos': 5683964203008000.0, 'train_loss': 1.188238959842258, 'epoch': 20.0})"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "#Запуск обучения модели\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQJ69Zz7VQWc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd482f13-0274-4b62-a80d-f6893c9b21cb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('fine-tune-bert/tokenizer_config.json',\n",
              " 'fine-tune-bert/special_tokens_map.json',\n",
              " 'fine-tune-bert/vocab.txt',\n",
              " 'fine-tune-bert/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "#Сохранение обученной модели\n",
        "model_path = \"fine-tune-bert\"\n",
        "model.save_pretrained(model_path)\n",
        "tokenizer.save_pretrained(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uuMyInSzVgfN",
        "outputId": "ba78a36e-737b-4cf6-edb2-90261bd23639",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        }
      ],
      "source": [
        "#функция для получения предикта\n",
        "def get_prediction():\n",
        "    test_pred = trainer.predict(test_dataset)\n",
        "    labels = np.argmax(test_pred.predictions, axis = -1)\n",
        "    return labels\n",
        "pred = get_prediction()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Вариант прогноза через сохраненную модель\n",
        "model_path = \"fine-tune-bert\"  # путь к сохраненной модели\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(model_path)\n",
        "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
        "\n",
        "#fin_text.tolist()\n",
        "encoded_input = tokenizer(fin_text, truncation=True, padding=True, return_tensors='pt')\n",
        "\n",
        "outputs = model(**encoded_input)\n",
        "logits = outputs.logits\n",
        "predicted_labels = logits.argmax(dim=1)\n",
        "\n",
        "print(predicted_labels)"
      ],
      "metadata": {
        "id": "lanPAdiQUD_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoding_dict = {value: key for key, value in label_mapping.items()}\n",
        "decoded_labels = np.array([decoding_dict[label] for label in pred])\n",
        "# Convert the decoded_labels to a DataFrame\n",
        "df = pd.DataFrame(decoded_labels, columns=['Label'])\n",
        "\n",
        "# Save the DataFrame as an XLS file\n",
        "df.to_excel('decoded_labels.xls', index=False)\n",
        "print(decoded_labels)"
      ],
      "metadata": {
        "id": "JNYKmYp3Gm0q",
        "outputId": "e6b4508b-a7b3-44e3-d03d-6988610555fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['A' 'BBB+' 'BBB' 'A-' 'A-' 'AA-' 'AA' 'AA-' 'A-' 'AA-' 'AAA' 'BBB' 'BB+'\n",
            " 'AAA' 'AA' 'AAA' 'A' 'BBB+' 'A+' 'A-' 'AAA' 'BBB' 'AA' 'A+' 'A+' 'BBB-'\n",
            " 'AAA' 'A-' 'A' 'AA+' 'BBB+' 'A-' 'A-' 'AA' 'A+' 'AA' 'A-' 'BBB-' 'AA+'\n",
            " 'AA-' 'AA' 'AA+' 'AA' 'BBB-' 'A-' 'AAA' 'A-' 'BB+' 'AAA' 'AA' 'A' 'A+'\n",
            " 'BBB+' 'BBB' 'BBB' 'A-' 'A' 'AAA' 'AAA' 'AA+' 'AA+' 'A' 'A' 'A+' 'A+'\n",
            " 'AAA' 'AAA' 'BB+' 'A' 'AAA' 'AA' 'AAA' 'BBB+' 'BBB-' 'A' 'AAA' 'BBB+'\n",
            " 'BBB-' 'AA+' 'BB+' 'AAA' 'BBB' 'AA' 'BBB-' 'BBB+' 'AA' 'AA-' 'AAA' 'A-'\n",
            " 'BBB-' 'A' 'AA' 'AAA' 'A-' 'BB+' 'AAA' 'BBB+' 'BBB' 'BBB+' 'A-' 'A-'\n",
            " 'BBB+' 'A-' 'AAA' 'A-' 'A-' 'AA-' 'A+' 'A' 'BBB+' 'AA' 'A+' 'AA+' 'AA'\n",
            " 'AA-' 'BBB' 'BB' 'BBB' 'BB+' 'BBB' 'BBB' 'A+' 'BB' 'A-' 'AA' 'A-' 'AAA'\n",
            " 'A-' 'AA+' 'BBB' 'A-' 'AA-' 'AAA' 'A-' 'BBB' 'AA' 'BBB' 'BB+' 'A' 'BB'\n",
            " 'A-' 'A-' 'AA' 'A+' 'A+' 'AAA' 'BBB+' 'AA+' 'AA' 'AA-' 'BB+' 'AA+' 'AAA'\n",
            " 'AA' 'AA-' 'A+' 'AA-' 'A' 'A' 'AAA' 'A-' 'AA' 'A-' 'BB' 'BBB-' 'AAA' 'A-'\n",
            " 'A+' 'A' 'A+' 'BBB+' 'AA' 'A-' 'A-' 'AAA' 'A-' 'A' 'A-' 'AA-' 'BB+' 'A'\n",
            " 'A-' 'A-' 'A' 'A-' 'A' 'AA+' 'BBB' 'AA' 'AA' 'AA+' 'BBB+' 'A' 'A-' 'AA'\n",
            " 'A+' 'AAA' 'AA' 'A+' 'BBB' 'AAA' 'AA' 'A-' 'AAA' 'A+' 'A' 'BB' 'BB' 'BB'\n",
            " 'BB+' 'BB' 'BB+' 'BB-' 'BB' 'BB' 'BB' 'BBB+' 'BBB' 'BBB' 'BBB' 'BBB-'\n",
            " 'A-' 'A-' 'A' 'BBB+' 'BBB+' 'A-' 'A-' 'A-' 'A' 'A-' 'A' 'BBB+' 'A' 'A+'\n",
            " 'BBB+' 'A-' 'A-' 'A-' 'BBB' 'BBB-' 'BBB-' 'A-' 'A-' 'A' 'A-' 'BBB+' 'A'\n",
            " 'BBB+' 'A-' 'A-' 'AA-' 'A-' 'A-' 'BB+' 'A' 'BBB+' 'BBB-' 'A' 'A-' 'A-'\n",
            " 'BB+' 'A' 'BBB+' 'BBB+' 'A' 'A-' 'A' 'A' 'A-' 'A+' 'A' 'A' 'A-' 'A-' 'A-'\n",
            " 'A-' 'A-' 'A-' 'BBB+' 'A-' 'A' 'A+' 'BBB+' 'BB+' 'A-' 'BBB' 'A-' 'A-' 'A'\n",
            " 'A-' 'BBB-' 'A' 'BBB+' 'A' 'A' 'A' 'A-' 'BBB+' 'BBB+' 'BB+' 'A+' 'BB+'\n",
            " 'A' 'A-' 'A-' 'A-' 'A-' 'BB' 'A' 'BBB+' 'A-' 'A' 'A-' 'A-' 'A-' 'BBB-'\n",
            " 'A-' 'BB' 'A-' 'A-' 'A' 'A-' 'BBB-' 'A-' 'A-' 'A+' 'BBB+' 'A-' 'A' 'BBB+'\n",
            " 'A-' 'BBB+' 'BBB' 'A-' 'A' 'A' 'BBB+' 'BBB+' 'A' 'A-' 'A-' 'A-' 'A' 'AA'\n",
            " 'A-' 'A' 'A-' 'BBB-' 'BBB-' 'A' 'BBB' 'A' 'A-' 'A-' 'A-' 'A+' 'A-' 'A-'\n",
            " 'AA' 'A-' 'A' 'A-' 'A-' 'BB+' 'A' 'BB' 'A-' 'A-' 'A-' 'A-' 'BBB-' 'BBB'\n",
            " 'A' 'A' 'A-' 'A-' 'BBB+' 'A' 'A-' 'A' 'A' 'A+' 'AA' 'A-' 'BBB-' 'A-' 'A-'\n",
            " 'A-' 'A-' 'A' 'A-' 'A' 'BBB+' 'A-' 'A-' 'A-' 'A-' 'A-' 'BB+' 'A-' 'BBB+'\n",
            " 'A-' 'A-' 'BB' 'BBB+' 'A-' 'A-' 'A-' 'AAA' 'A-' 'AAA' 'A-' 'AA' 'BB+'\n",
            " 'A-' 'A-' 'AAA' 'A-' 'A-' 'A-' 'A-']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-691ef1e2d56f>:7: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
            "  df.to_excel('decoded_labels.xls', index=False)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_uvGEDsVrmp"
      },
      "outputs": [],
      "source": [
        "#проверка полученного результата"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDJX2xtdVwRF"
      },
      "outputs": [],
      "source": [
        "#оценки качества модели\n",
        "print(classification_report(test_labels_encoded, pred))\n",
        "print(f1_score(test_labels_encoded, pred, average='micro'))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}